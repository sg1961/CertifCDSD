{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0eiKSLYG8XvO"
   },
   "source": [
    "# Projet : Conversion Rate Challenge üèÜ\n",
    "# Approche 2 : Traitement s√©par√© des pays puis consolidation des pr√©dictions\n",
    "# Mod√®les : Logistic Regression, SVM, Decision Tree Classifier, Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AGhdl7Bt2xZd"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LHgro65rxKF7"
   },
   "source": [
    "## Chargement des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "W1AU8AH8u0qd",
    "outputId": "00698a97-027b-493b-a2e4-33fdcc295abb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set with labels (our train) : (284580, 6)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./data/conversion_data_train.csv')\n",
    "print('Set with labels (our train) :', data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0XwjKBc63B1n"
   },
   "source": [
    "# Suppression outlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppression lignes avec age >= XX\n",
    "data = data[data[\"age\"] < 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement des Mod√®les : Logistic Regression, SVM, Decision Tree Classifier, Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "70MwsoCS3QD5"
   },
   "source": [
    "### Fonction de recherche du seuil de probabilit√© optimun pour un meilleur f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_prob_f1score(y_prob, y_real, seuil_step) :\n",
    "    best_seuil = 0.5\n",
    "    best_y_pred = np.array([0 if p[0] > best_seuil else 1 for p in y_prob])\n",
    "    best_f1_score = f1_score(y_real, best_y_pred)\n",
    "\n",
    "    \n",
    "    for seuil in np.arange(0, 1, seuil_step) :\n",
    "        y_pred = np.array([0 if p[0] > seuil else 1 for p in y_prob])\n",
    "        seuil_f1_score = f1_score(y_real, y_pred)\n",
    "        if seuil_f1_score > best_f1_score :\n",
    "            best_seuil = seuil\n",
    "            best_f1_score = seuil_f1_score\n",
    "            best_y_pred = y_pred\n",
    "\n",
    "    return (best_seuil, best_f1_score, best_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traitement des entrainements et pr√©dictions s√©parement pour chcun des pays\n",
    "### Objectif : mieux tenir compte des disparit√©s des d√©siquilibes du dataset par pays\n",
    "### Normalement, Les mod√®les devraient tenir compte nativement du facteur \"pays\" mais cel√† semble √™tre moins efficace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "W8K5DQEvvQgl",
    "outputId": "d280ebc9-4d4b-4723-b9fe-32513f898abc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Mod√®le : V01B : Logistic Regression\n",
      "\n",
      "['Germany']\t\tseuil : 0.617\tf1_score_train : 0.8088531187122736\tf1_score_test : 0.8158508158508159 (8184, 5)\n",
      "['US']\t\tseuil : 0.549\tf1_score_train : 0.7666116122474907\tf1_score_test : 0.7613670133729569 (112086, 5)\n",
      "['UK']\t\tseuil : 0.657\tf1_score_train : 0.7866500311915159\tf1_score_test : 0.7753934191702432 (30548, 5)\n",
      "['China']\t\tseuil : 0.833\tf1_score_train : 0.42016806722689076\tf1_score_test : 0.4262295081967213 (48385, 5)\n",
      "\n",
      "accuracy - train 0.9860443868817237\n",
      "f1 score - train 0.7719442165709598\n",
      "\n",
      "accuracy - test 0.9855812591508053\n",
      "f1 score - test 0.765657719398439\n",
      "\n",
      "[[191718   1061]\n",
      " [  1719   4705]]\n",
      "[[82133   488]\n",
      " [  743  2011]]\n",
      "\n",
      "*** Mod√®le : V02B : SVM\n",
      "\n",
      "['Germany']\t\tseuil : 0.922\tf1_score_train : 0.810379241516966\tf1_score_test : 0.8211009174311926 (8184, 5)\n",
      "['US']\t\tseuil : 0.891\tf1_score_train : 0.7661829652996845\tf1_score_test : 0.7641176470588236 (112086, 5)\n",
      "['UK']\t\tseuil : 0.924\tf1_score_train : 0.7876301672451878\tf1_score_test : 0.7744742567077593 (30548, 5)\n",
      "['China']\t\tseuil : 0.9560000000000001\tf1_score_train : 0.14492753623188406\tf1_score_test : 0.21052631578947367 (48385, 5)\n",
      "\n",
      "accuracy - train 0.9860569368935207\n",
      "f1 score - train 0.7719154177786902\n",
      "\n",
      "accuracy - test 0.9856398243045388\n",
      "f1 score - test 0.7666095564439368\n",
      "\n",
      "[[383451   2107]\n",
      " [  3448   9400]]\n",
      "[[164271    971]\n",
      " [  1481   4027]]\n",
      "\n",
      "*** Mod√®le : V03B : Decision Tree Classifier\n",
      "\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "['Germany']\t\tseuil : 0.5\tf1_score_train : 0.8259958071278826\tf1_score_test : 0.7830188679245284 (8184, 5)\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "['US']\t\tseuil : 0.6\tf1_score_train : 0.777859778597786\tf1_score_test : 0.7526511894525652 (112086, 5)\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "['UK']\t\tseuil : 0.589\tf1_score_train : 0.8100381194409149\tf1_score_test : 0.7498144023756496 (30548, 5)\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "['China']\t\tseuil : 0.75\tf1_score_train : 0.47761194029850745\tf1_score_test : 0.375 (48385, 5)\n",
      "\n",
      "accuracy - train 0.9862870204431325\n",
      "f1 score - train 0.7768306963317992\n",
      "\n",
      "accuracy - test 0.9852259638848219\n",
      "f1 score - test 0.7609602021478206\n",
      "\n",
      "[[575151   3186]\n",
      " [  5009  14263]]\n",
      "[[246318   1545]\n",
      " [  2239   6023]]\n",
      "\n",
      "*** Mod√®le : V04B : Random Forest Classifier\n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "['Germany']\t\tseuil : 0.579\tf1_score_train : 0.8459958932238193\tf1_score_test : 0.7971698113207547 (8184, 5)\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "['US']\t\tseuil : 0.606\tf1_score_train : 0.7796399751707014\tf1_score_test : 0.7571801566579635 (112086, 5)\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "['UK']\t\tseuil : 0.5740000000000001\tf1_score_train : 0.8151719704275152\tf1_score_test : 0.760268857356236 (30548, 5)\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "['China']\t\tseuil : 0.705\tf1_score_train : 0.6126126126126126\tf1_score_test : 0.4 (48385, 5)\n",
      "\n",
      "accuracy - train 0.9865237973323695\n",
      "f1 score - train 0.7807318467695826\n",
      "\n",
      "accuracy - test 0.9851800878477306\n",
      "f1 score - test 0.7600853282768428\n",
      "\n",
      "[[766957   4159]\n",
      " [  6579  19117]]\n",
      "[[328422   2062]\n",
      " [  2999   8017]]\n"
     ]
    }
   ],
   "source": [
    "# Les mod√®les test√©s\n",
    "models = ((\"V01B\", \"Logistic Regression\"),\n",
    "          (\"V02B\", \"SVM\"),\n",
    "          (\"V03B\", \"Decision Tree Classifier\"),\n",
    "          (\"V04B\", \"Random Forest Classifier\")\n",
    "        )\n",
    "\n",
    "# initialisation dataframe pour tracer le r√©sultat des diff√©rents mod√®les\n",
    "df_result = pd.DataFrame(columns = [\"Version\", \"Mod√®le\", \"f1Score_train\", \"f1Score_test\"])\n",
    "df_result_country = pd.DataFrame(columns = [\"Version\", \"Mod√®le\", \"country\", \"f1Score_train\", \"f1Score_test\"])\n",
    "\n",
    "# Initialisation de listes pour consolider les resultats des pr√©dictions faites s√©par√©ments sur les diff√©rents pays \n",
    "Y_test_total = []\n",
    "Y_test_pred_total = []\n",
    "Y_test_prob_total = []\n",
    "Y_train_total = []\n",
    "Y_train_pred_total = []\n",
    "Y_train_prob_total = []\n",
    "\n",
    "\n",
    "for model in models :\n",
    "    print(\"\\n*** Mod√®le : \" + model[0] + \" : \" + model[1] + \"\\n\")\n",
    "    \n",
    "    for country in [[\"Germany\"], [\"US\"], [\"UK\"], [\"China\"]] :\n",
    "\n",
    "        num_features = [\"age\", \"total_pages_visited\"]\n",
    "        cat_features = [\"source\", \"new_user\"]\n",
    "        features_list = num_features + cat_features\n",
    "        target_variable = 'converted'\n",
    "\n",
    "        dataset = data[(data[\"country\"].apply(lambda x : True if x in country else False))]\n",
    "        X = dataset.loc[:, features_list]\n",
    "        Y = dataset.loc[:, target_variable]\n",
    "\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, stratify=Y ,random_state=27)\n",
    "\n",
    "        numeric_transformer = Pipeline(steps=[(\"scaler\", StandardScaler()),])\n",
    "        categorical_transformer = Pipeline(steps=[(\"encoder\", OneHotEncoder(drop=\"first\")),])\n",
    "        preprocessor = ColumnTransformer(transformers=[\n",
    "                (\"num\", numeric_transformer, num_features),\n",
    "                (\"cat\", categorical_transformer, cat_features),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        X_train = preprocessor.fit_transform(X_train)\n",
    "        X_test = preprocessor.transform(X_test)\n",
    "\n",
    "        # Logistic Regression\n",
    "        if model[0] ==  \"V01B\" :\n",
    "            classifier = LogisticRegression(penalty='l1', solver='saga', max_iter=1000)\n",
    "            classifier.fit(X_train, Y_train)\n",
    "      \n",
    "        # SVM\n",
    "        if model[0] ==  \"V02B\" :\n",
    "            classifier = svm.SVC(kernel=\"poly\", probability=True, C=10, random_state=42)\n",
    "            classifier.fit(X_train, Y_train)\n",
    "\n",
    "        # Decision Tree Classifier\n",
    "        if model[0] ==  \"V03B\" :\n",
    "            # model = DecisionTreeClassifier()\n",
    "            params = {\n",
    "                'max_depth':[12, 14, 16],\n",
    "                'min_samples_split':[14,18,22],\n",
    "                'min_samples_leaf':[4,6,8]\n",
    "            }\n",
    "            gridsearch = GridSearchCV(DecisionTreeClassifier(), param_grid = params, scoring='f1', cv=5, verbose=1)\n",
    "            gridsearch.fit(X_train, Y_train)\n",
    "            classifier = gridsearch.best_estimator_\n",
    "\n",
    "\n",
    "        # Random Forest Classifier\n",
    "        if model[0] ==  \"V04B\" :\n",
    "            # model = RandomForestClassifier()\n",
    "            params={\n",
    "               'max_depth':[9],\n",
    "               'min_samples_split':[9],\n",
    "               'n_estimators':[40]\n",
    "            }\n",
    "            gridsearch = GridSearchCV(RandomForestClassifier(), param_grid = params, scoring='f1', cv=5, verbose=1)\n",
    "            gridsearch.fit(X_train, Y_train)\n",
    "            classifier = gridsearch.best_estimator_\n",
    "\n",
    "\n",
    "        # Predictions on training set\n",
    "        Y_train_pred = classifier.predict(X_train)\n",
    "        Y_train_prob = classifier.predict_proba(X_train)\n",
    "        \n",
    "        # Predictions on test set\n",
    "        Y_test_pred = classifier.predict(X_test)\n",
    "        Y_test_prob = classifier.predict_proba(X_test)\n",
    "        \n",
    "        (best_seuil, best_f1_score_train, best_y_pred) = best_prob_f1score(Y_train_prob, Y_train, .001)\n",
    "\n",
    "        Y_test_pred = [0 if p[0] > best_seuil else 1 for p in Y_test_prob]\n",
    "        f1_score_test = f1_score(np.array(Y_test), np.array(Y_test_pred))\n",
    "        print(f\"{country}\\t\\tseuil : {best_seuil}\\tf1_score_train : {best_f1_score_train}\\tf1_score_test : {f1_score_test}\", X_train.shape)\n",
    "\n",
    "        df_result_country.loc[len(df_result_country)] = [model[0], model[1], country, best_f1_score_train, f1_score_test]\n",
    "\n",
    "        Y_test_total += list(Y_test)\n",
    "        Y_test_pred_total += [0 if p[0] > best_seuil else 1 for p in Y_test_prob]\n",
    "        # Y_test_prob_total += [p for p in Y_test_prob]\n",
    "        Y_test_prob_total += list(Y_test_prob)\n",
    "        Y_train_total += list(Y_train)\n",
    "        Y_train_pred_total += [0 if p[0] > best_seuil else 1 for p in Y_train_prob]\n",
    "        # Y_train_prob_total += [p for p in Y_train_prob]\n",
    "        Y_train_prob_total += list(Y_train_prob)\n",
    "\n",
    "    print()\n",
    "    print(\"accuracy - train\", accuracy_score(np.array(Y_train_total), np.array(Y_train_pred_total)))\n",
    "    print(\"f1 score - train\", f1_score(np.array(Y_train_total), np.array(Y_train_pred_total)))\n",
    "    print()\n",
    "    print(\"accuracy - test\", accuracy_score(np.array(Y_test_total), np.array(Y_test_pred_total)))\n",
    "    print(\"f1 score - test\", f1_score(np.array(Y_test_total), np.array(Y_test_pred_total)))\n",
    "\n",
    "    print()\n",
    "    print(confusion_matrix(np.array(Y_train_total), np.array(Y_train_pred_total)))\n",
    "    print(confusion_matrix(np.array(Y_test_total), np.array(Y_test_pred_total)))\n",
    "\n",
    "    df_result.loc[len(df_result)] = [model[0], model[1], f1_score(np.array(Y_train_total), np.array(Y_train_pred_total)), f1_score(np.array(Y_test_total), np.array(Y_test_pred_total))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Version</th>\n",
       "      <th>Mod√®le</th>\n",
       "      <th>f1Score_train</th>\n",
       "      <th>f1Score_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V01B</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.771944</td>\n",
       "      <td>0.765658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>V02B</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.771915</td>\n",
       "      <td>0.766610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V03B</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>0.776831</td>\n",
       "      <td>0.760960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V04B</td>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.780732</td>\n",
       "      <td>0.760085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Version                    Mod√®le  f1Score_train  f1Score_test\n",
       "0    V01B       Logistic Regression       0.771944      0.765658\n",
       "1    V02B                       SVM       0.771915      0.766610\n",
       "2    V03B  Decision Tree Classifier       0.776831      0.760960\n",
       "3    V04B  Random Forest Classifier       0.780732      0.760085"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Version</th>\n",
       "      <th>Mod√®le</th>\n",
       "      <th>country</th>\n",
       "      <th>f1Score_train</th>\n",
       "      <th>f1Score_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V01B</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>[Germany]</td>\n",
       "      <td>0.808853</td>\n",
       "      <td>0.815851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>V01B</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>[US]</td>\n",
       "      <td>0.766612</td>\n",
       "      <td>0.761367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V01B</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>[UK]</td>\n",
       "      <td>0.786650</td>\n",
       "      <td>0.775393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V01B</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>[China]</td>\n",
       "      <td>0.420168</td>\n",
       "      <td>0.426230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V02B</td>\n",
       "      <td>SVM</td>\n",
       "      <td>[Germany]</td>\n",
       "      <td>0.810379</td>\n",
       "      <td>0.821101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>V02B</td>\n",
       "      <td>SVM</td>\n",
       "      <td>[US]</td>\n",
       "      <td>0.766183</td>\n",
       "      <td>0.764118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>V02B</td>\n",
       "      <td>SVM</td>\n",
       "      <td>[UK]</td>\n",
       "      <td>0.787630</td>\n",
       "      <td>0.774474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>V02B</td>\n",
       "      <td>SVM</td>\n",
       "      <td>[China]</td>\n",
       "      <td>0.144928</td>\n",
       "      <td>0.210526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>V03B</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>[Germany]</td>\n",
       "      <td>0.825996</td>\n",
       "      <td>0.783019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>V03B</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>[US]</td>\n",
       "      <td>0.777860</td>\n",
       "      <td>0.752651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>V03B</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>[UK]</td>\n",
       "      <td>0.810038</td>\n",
       "      <td>0.749814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>V03B</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>[China]</td>\n",
       "      <td>0.477612</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>V04B</td>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>[Germany]</td>\n",
       "      <td>0.845996</td>\n",
       "      <td>0.797170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>V04B</td>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>[US]</td>\n",
       "      <td>0.779640</td>\n",
       "      <td>0.757180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>V04B</td>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>[UK]</td>\n",
       "      <td>0.815172</td>\n",
       "      <td>0.760269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>V04B</td>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>[China]</td>\n",
       "      <td>0.612613</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Version                    Mod√®le    country  f1Score_train  f1Score_test\n",
       "0     V01B       Logistic Regression  [Germany]       0.808853      0.815851\n",
       "1     V01B       Logistic Regression       [US]       0.766612      0.761367\n",
       "2     V01B       Logistic Regression       [UK]       0.786650      0.775393\n",
       "3     V01B       Logistic Regression    [China]       0.420168      0.426230\n",
       "4     V02B                       SVM  [Germany]       0.810379      0.821101\n",
       "5     V02B                       SVM       [US]       0.766183      0.764118\n",
       "6     V02B                       SVM       [UK]       0.787630      0.774474\n",
       "7     V02B                       SVM    [China]       0.144928      0.210526\n",
       "8     V03B  Decision Tree Classifier  [Germany]       0.825996      0.783019\n",
       "9     V03B  Decision Tree Classifier       [US]       0.777860      0.752651\n",
       "10    V03B  Decision Tree Classifier       [UK]       0.810038      0.749814\n",
       "11    V03B  Decision Tree Classifier    [China]       0.477612      0.375000\n",
       "12    V04B  Random Forest Classifier  [Germany]       0.845996      0.797170\n",
       "13    V04B  Random Forest Classifier       [US]       0.779640      0.757180\n",
       "14    V04B  Random Forest Classifier       [UK]       0.815172      0.760269\n",
       "15    V04B  Random Forest Classifier    [China]       0.612613      0.400000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_result)\n",
    "display(df_result_country)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Projets_template.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
